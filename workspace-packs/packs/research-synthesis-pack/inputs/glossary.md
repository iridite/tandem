# Glossary of Terms

## Core Concepts

### Local-First AI

AI systems that run primarily on local hardware (user devices, on-premises servers) rather than relying on cloud infrastructure. Key principle: data never leaves the local environment unless explicitly authorized.

### Cloud-Based AI

Traditional AI services where data is transmitted to remote servers for processing. Examples include OpenAI APIs, Google Cloud AI, AWS AI services.

### Edge AI

AI processing performed on edge devices (IoT sensors, mobile phones, local servers) near the data source, reducing latency and bandwidth requirements.

### Federated Learning

A machine learning approach where models are trained across multiple decentralized devices without exchanging raw data samples.

## Security Terms

### Threat Surface (Attack Surface)

The sum of all points where an unauthorized user can try to enter data to or extract data from a system.

### Zero-Trust Architecture

A security framework requiring all users to be authenticated and authorized continuously, even inside the network perimeter.

### Data Sovereignty

The concept that digital data is subject to the laws of the country in which it is located or processed.

### End-to-End Encryption

A method where data is encrypted on the sender's device and decrypted only on the recipient's device, with no intermediate parties able to decrypt.

## Compliance and Governance

### GDPR (General Data Protection Regulation)

EU regulation on data protection and privacy, with strict requirements for personal data handling.

### HIPAA (Health Insurance Portability and Accountability Act)

US regulation establishing security and privacy requirements for protected health information.

### SOC 2 (System and Organization Controls 2)

Auditing framework for service organizations, assessing security, availability, processing integrity, confidentiality, and privacy.

### Data Localization

Requirements that certain types of data must be stored and processed within a specific country's borders.

## Technical Terms

### Inference Latency

The time delay between submitting a request to an AI model and receiving the response.

### Model Quantization

Reducing the precision of a model's weights (e.g., from 32-bit to 8-bit) to decrease size and increase speed.

### Local Model Deployment

The process of installing and running AI models on local hardware rather than accessing them via API.

### Vector Database

A database designed to store, manage, and index vector embeddings for similarity search capabilities.

## Organizational Terms

### Shadow IT

Systems or solutions built and used inside organizations without explicit organizational approval.

### IT Governance

The processes and structures that direct and control organizational IT activities.

### Digital Transformation

The integration of digital technology into all areas of an organization, fundamentally changing how it operates.

### Change Management

A systematic approach to dealing with changes in an organization, including adoption of new technologies.
